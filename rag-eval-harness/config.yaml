# Configuration for the RAG Evaluation Harness

# The name of the implementation file in nlp/rag/implementations/ (without .py)
rag_implementation_to_test: "mmr_summary_rag"

dataset:
  name: "multi_news"
  # Path to the ground truth file (will be created by the download script)
  ground_truth_file: "datasets/ground_truth/multi_news_test.json"
  # Number of samples to use from the dataset for the benchmark
  num_samples: 50

evaluation_params:
  top_k: 3

results:
  output_dir: "results/"
