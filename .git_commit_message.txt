feat(rag): Add EnrichedContextRAG with ingestion-time expansion

This commit introduces a new, advanced RAG strategy, `EnrichedContextRAG`, based on the concept of ingestion-time document expansion.

This implementation uses a `fast_llm` during the `ingest` phase to enrich each document chunk. For each chunk, it generates:
1.  A concise summary to capture the high-level topic.
2.  A hypothetical question that the chunk directly answers.

This enriched text (question + summary + original content) is then embedded and indexed in the vector store, creating a much more semantically rich target for retrieval. The `query` method retrieves these enriched documents but intelligently passes the *original* text to the final generator LLM, ensuring clean and accurate answers.

This strategy is designed to significantly improve retrieval precision by creating better representations of the source documents. It is now available as a selectable option in the generic UI and evaluation harness.